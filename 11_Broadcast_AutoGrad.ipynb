{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenU_DL_Maman_11_Introduction_Broadcast_AutoGrad.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yaniv92648/OpenU_DL/blob/main/OpenU_DL_Maman_11_Introduction_Broadcast_AutoGrad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "לינק להקלטה\n",
        "\n",
        "https://drive.google.com/file/d/1T7oWU194Szid_QIJNfRn7rTu_yQgPWmY/view\n"
      ],
      "metadata": {
        "id": "26R65CCdS4Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "o6rnfgtYVE98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWAQehRHI9yQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5fd7ef03-3ba3-4f12-bfae-1221daa73ac7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Question 1\n",
        "\n",
        "def my_sampler(size, dist, requires_grad=False):\n",
        "    # Sanity\n",
        "    assert dist.sum() == 1, 'Sum of probabilities should equal to 1' \n",
        "    assert dist.all() > 0, 'Probabilities must be positive'\n",
        "    # Algorithm\n",
        "    U = torch.rand(size) # Generates a tensor with \"size\" ranom numbers from 0 to 1 (uniformly)\n",
        "    I = torch.where(U < dist[0], torch.tensor(float(0)), U) # 1st condition\n",
        "    I = torch.where(U >= 1-dist[-1], torch.tensor(float(dist.shape[0]-1)), I) # 2nd condition\n",
        "    cumsum_dist = dist.cumsum(dim=0) # Accumulative sums of dist\n",
        "    # 3rd condition\n",
        "    for k in range(1, dist.numel() - 1):\n",
        "      I = torch.where((U >= cumsum_dist[k-1]) & (U < cumsum_dist[k]), torch.tensor(float(k)), I)\n",
        "    I.requires_grad = requires_grad # indicates if gradients need to be computed\n",
        "    return I\n",
        "\n",
        "plt.hist(my_sampler(size=10**4, dist=torch.tensor([0.1, 0.2, 0.7]), requires_grad=True).detach().numpy());"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1 - Bonus\n",
        "\n",
        "def alias_sampler(size, dist, requires_grad=False):\n",
        "  # Sanity\n",
        "  assert dist.sum() == 1 # Sum of probabilities should equal to 1\n",
        "  assert dist.all() > 0 # Probabilities must be positive\n",
        "  # Creating probabilities table (U) & alias table (K)\n",
        "  n = dist.shape[0]\n",
        "  U = n * dist # How much \"liquid\" in every bucket\n",
        "  # Each bucket is made of \"liquids\" that belongs to two buckets.\n",
        "  # A key-value in K is the 1st & 2nd bucket, correspondingly\n",
        "  K = torch.arange(n)\n",
        "  while U[U < 1].any() and U[U > 1].any():\n",
        "    i = (U > 1).nonzero()[0].item() # Overfull bucket index\n",
        "    j = (U < 1).nonzero()[0].item() # Underfull bucket index\n",
        "    K[j] = i # The i'th bucket fills the j's bucket\n",
        "    U[i] -= 1 - U[j] # Remove the filled \"liquids\" from U[i]\n",
        "    U[j] = 1 # Bucket U[j] is now full\n",
        "  # Algorithm\n",
        "  U = n * dist\n",
        "  X = torch.rand(size) # Random number between 0 & 1 uniformly\n",
        "  I = (n * X).to(torch.int64) # Random bucket choice\n",
        "  Y = n * X - I # Random threshold in chosen bucket\n",
        "  return torch.where(Y < U[I], I, K[I])\n",
        "\n",
        "plt.hist(alias_sampler(size=10**4, dist=torch.tensor([0.1, 0.2, 0.7]), requires_grad=True).detach().numpy());"
      ],
      "metadata": {
        "id": "QhiI4-wgRp5r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ace14f5a-41e1-4608-e811-fb954990857b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2 - א\n",
        "\n",
        "def broadcast_left_to_right(A, B):\n",
        "  # Sanity\n",
        "  if A.shape == B.shape:\n",
        "    return A\n",
        "  # First check if possible\n",
        "  A_shape_rev, B_shape_rev = A.shape[::-1], B.shape[::-1]\n",
        "  for i, dim_A in enumerate(A_shape_rev):\n",
        "    dim_B = B_shape_rev[i]\n",
        "    assert dim_A == dim_B or dim_A == 1, 'Broadcasting not possible'\n",
        "  # Broascast\n",
        "  for i, dim_A in enumerate(A.shape):\n",
        "    dim_B = B.shape[i]\n",
        "    if dim_A < dim_B:\n",
        "      C = A.clone()\n",
        "      while C.shape[i] < dim_B:\n",
        "        C = torch.cat((C, A), dim=i)\n",
        "  return C"
      ],
      "metadata": {
        "id": "9-M566gdcNoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2 - א - Tests\n",
        "\n",
        "# Sanity\n",
        "a = torch.tensor([[1, 7], [2, 4]])\n",
        "b = torch.tensor([[1, 2], [3, 4]])\n",
        "print(f'Sanity test: {broadcast_left_to_right(a, b)}')\n",
        "\n",
        "# Not possible\n",
        "a = torch.tensor([[1, 7], [2, 4]])\n",
        "b = torch.tensor([[1, 2], [3, 4], [2, 2]])\n",
        "try:\n",
        "  print(f'Not possible test: {broadcast_left_to_right(a, b)}')\n",
        "except Exception as e: \n",
        "  print(f'Not possible test: {e}')\n",
        "\n",
        "# Possible\n",
        "a = torch.tensor([[1, 7]])\n",
        "b = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
        "print(f'Possible test: {broadcast_left_to_right(a, b)}')"
      ],
      "metadata": {
        "id": "Do_2F9LdKXoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c40f5a-708e-4fb2-9d92-8e8e6aa374de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity test: tensor([[1, 7],\n",
            "        [2, 4]])\n",
            "Not possible test: Broadcasting not possible\n",
            "Possible test: tensor([[1, 7],\n",
            "        [1, 7],\n",
            "        [1, 7],\n",
            "        [1, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2 - ב\n",
        "\n",
        "def can_broadcast_together(A, B):\n",
        "  # Sanity\n",
        "  if A.shape == B.shape:\n",
        "    return True, A.shape\n",
        "  A_shape_rev, B_shape_rev = A.shape[::-1], B.shape[::-1]\n",
        "  for i, dim_A in enumerate(A_shape_rev):\n",
        "    dim_B = B_shape_rev[i]\n",
        "    if dim_A != dim_B and dim_A != 1 and dim_B != 1:\n",
        "      return False, None\n",
        "  return True, torch.Size(torch.max(torch.tensor(A.shape), torch.tensor(B.shape)))"
      ],
      "metadata": {
        "id": "clM5JJRVQOZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2 - ב - Tests\n",
        "\n",
        "# Sanity\n",
        "a = torch.tensor([[1, 7, 9]])\n",
        "b = torch.tensor([[2], [4]])\n",
        "print(f'Sanity test: {can_broadcast_together(a, b)}')\n",
        "\n",
        "# Possible\n",
        "a = torch.tensor([[1, 7, 9]])\n",
        "b = torch.tensor([[2], [4]])\n",
        "print(f'Possible test: {can_broadcast_together(a, b)}')\n",
        "\n",
        "# Not possible\n",
        "a = torch.tensor([[1, 7, 9]])\n",
        "b = torch.tensor([[2, 5], [4, 6]])\n",
        "print(f'Not possible test: {can_broadcast_together(a, b)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw_wU6aCSDsK",
        "outputId": "e82d4b19-d9aa-4694-8adb-d0f37c211a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity test: (True, torch.Size([2, 3]))\n",
            "Possible test: (True, torch.Size([2, 3]))\n",
            "Not possible test: (False, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2 - ג\n",
        "\n",
        "def broadcast_together(A, B):\n",
        "  # Sanity\n",
        "  if A.shape == B.shape:\n",
        "    return A, B\n",
        "  can_broadcast, size = can_broadcast_together(A, B)\n",
        "  if not can_broadcast:\n",
        "    return 'Cannot Broadcast!'\n",
        "  # Broascast\n",
        "  zeros = torch.zeros(size)\n",
        "  A_broadcasted = broadcast_left_to_right(A, zeros)\n",
        "  B_broadcasted = broadcast_left_to_right(B, zeros)\n",
        "  return A_broadcasted, B_broadcasted"
      ],
      "metadata": {
        "id": "eoYvMx_nSqh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2 - ד\n",
        "\n",
        "a = torch.tensor([[1, 7]])\n",
        "b = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
        "print(f'1. {torch.all(a.expand_as(b) == broadcast_left_to_right(a, b))}')\n",
        "\n",
        "a = torch.tensor([[1, 7, 9]])\n",
        "b = torch.tensor([[2, 5], [4, 6]])\n",
        "print(f'2. {broadcast_together(a, b)}')\n",
        "try:\n",
        "  torch.broadcast_tensors(a, b)\n",
        "except Exception as e: \n",
        "  print(e)\n",
        "\n",
        "a = torch.tensor([[1, 7, 9]])\n",
        "b = torch.tensor([[2], [4]])\n",
        "br_to_a_b, br_to_b_a = broadcast_together(a, b)\n",
        "br_te_a_b, br_te_b_a = torch.broadcast_tensors(a, b)\n",
        "print(f'3. {torch.all(br_to_a_b == br_te_a_b)}')\n",
        "print(f'4. {torch.all(br_to_b_a == br_te_b_a)}')"
      ],
      "metadata": {
        "id": "yFUbSRp6a1H9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e9df5d7-070f-41d6-c747-79faed8ef15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. True\n",
            "2. Cannot Broadcast!\n",
            "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1\n",
            "3. True\n",
            "4. True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "class MyScalar:\n",
        "\n",
        "  # gradient_2 & parent_2 is for the bonus\n",
        "  def __init__(self, value=None, gradient_1=1, gradient_2=1, parent_1=None, parent_2=None):\n",
        "    self.value = value if (type(value) == torch.Tensor) else torch.tensor(value)\n",
        "    self.gradient_1 = gradient_1 if (type(gradient_1) == torch.Tensor) else torch.tensor(gradient_1)\n",
        "    self.gradient_2 = gradient_2 if (type(gradient_2) == torch.Tensor) else torch.tensor(gradient_2)\n",
        "    self.parent_1 = parent_1\n",
        "    self.parent_2 = parent_2\n",
        "    self.ID = str(hash(self))\n",
        "\n",
        "\n",
        "gradient_dict = defaultdict(lambda:0)\n",
        "\n",
        "\n",
        "# Regular + Bonus\n",
        "def get_gradient(my_scalar):\n",
        "  if my_scalar.ID not in gradient_dict:\n",
        "    gradient_dict[my_scalar.ID] = 1\n",
        "  if my_scalar.parent_1 is not None:\n",
        "    gradient_dict[my_scalar.parent_1.ID] += gradient_dict[my_scalar.ID] * my_scalar.gradient_1.item()\n",
        "    get_gradient(my_scalar.parent_1)\n",
        "  if my_scalar.parent_2 is not None:\n",
        "    gradient_dict[my_scalar.parent_2.ID] += gradient_dict[my_scalar.ID] * my_scalar.gradient_2.item()\n",
        "    get_gradient(my_scalar.parent_2)\n",
        "  return gradient_dict\n",
        "\n",
        "\n",
        "\n",
        "class MathLibrary:\n",
        "\n",
        "  @staticmethod\n",
        "  def exp(my_scalar):\n",
        "    return MyScalar(value=torch.exp(my_scalar.value), \n",
        "                    gradient_1=torch.exp(my_scalar.value), \n",
        "                    parent_1=my_scalar)\n",
        "  \n",
        "  @staticmethod\n",
        "  def ln(my_scalar):\n",
        "    return MyScalar(value=torch.log(my_scalar.value),\n",
        "                    gradient_1=1/my_scalar.value, \n",
        "                    parent_1=my_scalar)\n",
        "\n",
        "  @staticmethod\n",
        "  def sin(my_scalar):\n",
        "    return MyScalar(value=torch.sin(my_scalar.value),\n",
        "                    gradient_1=torch.cos(my_scalar.value),\n",
        "                    parent_1=my_scalar)\n",
        "    \n",
        "  @staticmethod\n",
        "  def cos(my_scalar):\n",
        "    return MyScalar(value=torch.cos(my_scalar.value),\n",
        "                    gradient_1=-torch.sin(my_scalar.value),\n",
        "                    parent=my_scalar)\n",
        "  \n",
        "  @staticmethod\n",
        "  def power(my_scalar, exponent):\n",
        "    return MyScalar(value=torch.pow(my_scalar.value, exponent),\n",
        "                    gradient_1=exponent*torch.pow(my_scalar.value, exponent-1),\n",
        "                    parent_1=my_scalar)\n",
        "  \n",
        "  @staticmethod\n",
        "  def addition(my_scalar, addition_value):\n",
        "    return MyScalar(value=my_scalar.value+addition_value,\n",
        "                    gradient_1=1, \n",
        "                    parent_1=my_scalar)\n",
        "    \n",
        "  @staticmethod\n",
        "  def product(my_scalar, product_value):\n",
        "    return MyScalar(value=my_scalar.value*product_value,\n",
        "                    gradient_1=product_value, \n",
        "                    parent_1=my_scalar)\n",
        "  \n",
        "  # Bonus\n",
        "  @staticmethod\n",
        "  def product_scalars(my_scalar_1, my_scalar_2):\n",
        "    return MyScalar(value=my_scalar_1.value*my_scalar_2.value,\n",
        "                    gradient_1=my_scalar_2.value, \n",
        "                    gradient_2=my_scalar_1.value, \n",
        "                    parent_1=my_scalar_1,\n",
        "                    parent_2=my_scalar_2)\n",
        "\n",
        "  # Bonus\n",
        "  @staticmethod\n",
        "  def division_scalars(my_scalar_1, my_scalar_2):\n",
        "    return MyScalar(value=my_scalar_1.value/my_scalar_2.value,\n",
        "                    gradient_1=1/my_scalar_2.value, \n",
        "                    gradient_2=-my_scalar_1.value*pow(my_scalar_2.value, -2),\n",
        "                    parent_1=my_scalar_1,\n",
        "                    parent_2=my_scalar_2)\n",
        "    \n",
        "  # Bonus\n",
        "  @staticmethod\n",
        "  def addition_scalars(my_scalar_1, my_scalar_2):\n",
        "    return MyScalar(value=my_scalar_1.value+my_scalar_2.value,\n",
        "                    gradient_1=1,\n",
        "                    gradient_2=1,\n",
        "                    parent_1=my_scalar_1,\n",
        "                    parent_2=my_scalar_2)"
      ],
      "metadata": {
        "id": "C-siha6sdz5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tests for Q3\n",
        "\n",
        "a_user = MyScalar(value=2) # a_user == 2\n",
        "a_user.ID = 'a_user'\n",
        "b_user = MathLibrary.power(a_user, 2) # b_user == 4\n",
        "b_user.ID = 'b_user'\n",
        "c_user = MathLibrary.exp(b_user) # c_user == ~54.59\n",
        "c_user.ID = 'c_user'\n",
        "\n",
        "a_cp = torch.tensor(2., requires_grad=True) # a_cp == 2\n",
        "b_cp = torch.pow(a_cp, 2) # b_cp == 4\n",
        "b_cp.retain_grad() # Enables this Tensor to have their grad populated during backward()\n",
        "c_cp = torch.exp(b_cp) # c_cp == ~54.59\n",
        "c_cp.retain_grad() # Enables this Tensor to have their grad populated during backward()\n",
        "c_cp.backward() # Computes the gradient of current tensor w.r.t. graph leaves.\n",
        "\n",
        "gradient_dict.clear()\n",
        "\n",
        "print(f'a_user = {a_user.value}, b_user = {b_user.value}, c_user = {c_user.value}')\n",
        "print(f'a_cp = {a_cp.item()}, b_cp = {b_cp.item()}, c_cp = {c_cp.item()}\\n')\n",
        "print(dict(get_gradient(c_user)))\n",
        "print({'c_cp': c_cp.grad.item(), 'b_cp': b_cp.grad.item(), 'a_cp': a_cp.grad.item()})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MjzY-Zwhpr7",
        "outputId": "539b9961-7aec-4a55-d69e-75ae3b675c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a_user = 2, b_user = 4, c_user = 54.598148345947266\n",
            "a_cp = 2.0, b_cp = 4.0, c_cp = 54.598148345947266\n",
            "\n",
            "{'c_user': 1, 'b_user': 54.598148345947266, 'a_user': 218.39259338378906}\n",
            "{'c_cp': 1.0, 'b_cp': 54.598148345947266, 'a_cp': 218.39259338378906}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tests for Q3 - Bonus\n",
        "\n",
        "a_user = MyScalar(value=2) # a_user == 2\n",
        "a_user.ID = 'a_user'\n",
        "b_user = MathLibrary.power(a_user, 4) # b_user == 16\n",
        "b_user.ID = 'b_user'\n",
        "c_user = MathLibrary.exp(a_user) # c_user == ~7.38\n",
        "c_user.ID = 'c_user'\n",
        "d_user = MathLibrary.product_scalars(b_user, c_user) # d_user == ~118.22\n",
        "d_user.ID = 'd_user'\n",
        "\n",
        "a_cp = torch.tensor(2., requires_grad=True) # a_cp == 2\n",
        "b_cp = torch.pow(a_cp, 4) # b_cp == 16\n",
        "b_cp.retain_grad() # Enables this Tensor to have their grad populated during backward()\n",
        "c_cp = torch.exp(a_cp) # c_cp == ~7.38\n",
        "c_cp.retain_grad() # Enables this Tensor to have their grad populated during backward()\n",
        "d_cp = b_cp * c_cp # d_cp == ~118.22\n",
        "d_cp.retain_grad() # Enables this Tensor to have their grad populated during backward()\n",
        "d_cp.backward() # Computes the gradient of current tensor w.r.t. graph leaves.\n",
        "\n",
        "gradient_dict.clear()\n",
        "\n",
        "print(f'a_user = {a_user.value}, b_user = {b_user.value}, c_user = {c_user.value}, d_user = {d_user.value}')\n",
        "print(f'a_cp = {a_cp.item()}, b_cp = {b_cp.item()}, c_cp = {c_cp.item()},  d_cp = {d_cp.item()}\\n')\n",
        "print(dict(get_gradient(d_user)))\n",
        "print({'d_cp': d_cp.grad.item(), 'c_cp': c_cp.grad.item(), 'b_cp': b_cp.grad.item(), 'a_cp': a_cp.grad.item()})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3l60orV6mCb",
        "outputId": "d9fadbba-8c42-48d2-ea39-bd8183b276dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a_user = 2, b_user = 16, c_user = 7.389056205749512, d_user = 118.22489929199219\n",
            "a_cp = 2.0, b_cp = 16.0, c_cp = 7.389056205749512,  d_cp = 118.22489929199219\n",
            "\n",
            "{'d_user': 1, 'b_user': 7.389056205749512, 'a_user': 354.67469787597656, 'c_user': 16}\n",
            "{'d_cp': 1.0, 'c_cp': 16.0, 'b_cp': 7.389056205749512, 'a_cp': 354.6746826171875}\n"
          ]
        }
      ]
    }
  ]
}
